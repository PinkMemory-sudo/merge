# **准备模板虚拟机**



修改静态IP

```bash
vim /etc/sysconfig/network-scripts/ifcfg-ens33
```

修改主机名

```
vim /etc/hostname
```

修改hosts

```
vim /etc/hosts
```

给账户添加root权限(可以使用sudo命令)

```
vim /etc/sudoers
```

 在%wheel 这行下面添加一行 

```
pk ALL=(ALL) NOPASSWD:ALL
```

关闭防火墙

在企业开发时，通常单个服务器的防火墙时关闭的。公司整体对外会设置非常安 全的防火墙 

**卸载自带的JDK**

```
rpm -qa | grep -i java | xargs -n1 | rpm -e --nodeps
```

配置Hadoop环境变量

```
HADOOP_HOME
HADOOP/bin
HADOOP/sbin
```

**Hadoop目录**

shard  官方案例







# 完全分布式的搭建



克隆

修改静态IP

修改hostname

修改hosts映射

集群配置



NameServer和NN2不能配置在一台服务器上

ResourceManager也很耗内存，不能放到同一个节点

|      | Hadoop100          | Hadoop101                | Hadoop102     |
| ---- | ------------------ | ------------------------ | ------------- |
| HDFS | NameNode，DataNode | DataNode                 | 2NN，DataNode |
| Yarn | NodeManager        | ResourceNode,NodeManager | DataManager   |



**文件分发脚本**

```

```



**密钥配置**



## **配置文件说明**

两类：默认配置文件，自定义配置文件。

自定义配置文件： core-site.xml、hdfs-site.xml、yarn-site.xml、mapred-site.xml 四个配置文件存放在 $HADOOP_HOME/etc/hadoop 这个路径上，用户可以根据项目需求重新进行修改配置。 



**core-site.xml**

```xml
<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
<configuration>
 <!-- 指定 NameNode 的地址 -->
 <property>
 <name>fs.defaultFS</name>
 <value>hdfs://hadoop102:8020</value>
 </property>
 <!-- 指定 hadoop 数据的存储目录 -->
 <property>
 <name>hadoop.tmp.dir</name>
 <value>/opt/module/hadoop-3.1.3/data</value>
 </property>
 <!-- 配置 HDFS 网页登录使用的静态用户为 atguigu -->
 <property>
 <name>hadoop.http.staticuser.user</name>
 <value>atguigu</value>
 </property>
</configuration>

```



**hdfs-site.xml**

```xml
<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
<configuration>
<!-- nn web 端访问地址-->
<property>
 <name>dfs.namenode.http-address</name>
 <value>hadoop102:9870</value>
 </property>
<!-- 2nn web 端访问地址-->
 <property>
 <name>dfs.namenode.secondary.http-address</name>
 <value>hadoop104:9868</value>
 </property>
</configuration>
```



**yarn-site.xml**

```xml
<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
<configuration>
 <!-- 指定 MR 走 shuffle -->
 <property>
 <name>yarn.nodemanager.aux-services</name>
 <value>mapreduce_shuffle</value>
 </property>
 <!-- 指定 ResourceManager 的地址-->
 <property>
 <name>yarn.resourcemanager.hostname</name>
 <value>hadoop103</value>
 </property>
 <!-- 环境变量的继承 -->
 <property>
 <name>yarn.nodemanager.env-whitelist</name>

<value>JAVA_HOME,HADOOP_COMMON_HOME,HADOOP_HDFS_HOME,HADOOP_CONF_DIR,CLASSPATH_PREPEND_DISTCACHE,HADOOP_YARN_HOME,HADOOP_MAP
RED_HOME</value>
 </property>
</configuration>
```



**mapred-site.xml**

```xml
<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
<configuration>
<!-- 指定 MapReduce 程序运行在 Yarn 上 -->
 <property>
 <name>mapreduce.framework.name</name>
 <value>yarn</value>
 </property>
</configuration>
```



**配置workers**

```
# 默认配置为localhost
vim /opt/module/hadoop3.1.3/etc/hadoop/workers
```

```
hadoop102
hadoop103
hadoop104
```



**设置ssh登录密钥**



## 启动集群

**第一次启动需要格式NameNode**

```base
hdfs namenode -format
```

格式化完成后多出data和log目录。

注意：格式 化 NameNode，会产生新的集群 id，导致 NameNode 和 DataNode 的集群 id 不一致，集群找不到已往数据。如果集群在运行过程中报错，需要重新格式化 NameNode 的话，一定要先停 止 namenode 和 datanode 进程，并且要删除所有机器的 data 和 logs 目录，然后再进行格式化。 



**启动HDFS**

```bash
sbin/start-dfs.sh
```

![1648392501717](E:\note\2\merge\BigData\Img\Hadoop启动HDFS.png)

**启动ResourceManager**

在配置了ResourceManager的节点上启动ResourceManager

```bash
sbin/start-yarn.sh
```



**Web端查看NameNode**



**Web端查看ResourceManager**



## 配置历史服务器

任务执行的历史



sheffle



