 **为什么使用消息队列**

 你们公司有个什么业务场景，这个业务场景有个什么技术挑战，如果不用MQ可能会很麻烦，但是你现在用了MQ之后带给了你很多的好处 。



**MQ的优点与缺点**

优点：异步处理，应用解耦，削峰

缺点：

* 可用性降低：考虑MQ宕机的情况

* 复杂性提高：要考虑MQ的消息丢失与重复消费等问题
* 一致性问题：



**MQ对比**

1. 使用场景：Kafka适合日志处理；RocketMQ适合业务处理
2. 性能：Kafka吞吐量更高，单机百万/秒；RocketMQ单机10万/秒， Kafka一个topic有很多partition，代表很多目录，每个目录下有很多segment，每个代表一个消息文件，而RocketMQ存储消息只有commitLog文件 
3.  Kafka不支持定时，事务消息等
4.  Kafka超过64个队列（partition）性能下降严重，而RocketMQ最高支持5万个队列   



**MQ怎么选择**





**MQ的协议**

JMS：Java消息服务。它便于消息系统中的Java应用程序进行消息交换，并且通过提供标准的产生、发送、接收消息的接口，简化企业应用的开发。ActiveMQ是该协议的典型实现。

 AMQP： 应用 层标准。。 RabbitMQ是该协议的典型实现。



**怎么保证消息不丢失**

1. 消费者保证投递发送成功

生产者有三种发送方式：同步、异步和OneWay。同步就是发送消息后进入阻塞，等待确认，异步就是异步的，发送后直接返回，消息发送成功后回掉自定义的接口，Oneway就是只管发送。

生产者采用同步的方式确保发送到了MQ，发送失败时可以指定重试次数，最后还不行就存入DB。也可以采用异步回调的方式，将消息存储补偿表中

2. Broker确保持久化

Broker的刷盘策略分为同步和异步。同步是等消息持久化后再返回ACK，异步是指将消息写入PageCache后直接放回。可以采用同步刷盘的策略，确保消息被持久化。另外，MQ应该采用多主多从的方式来保证高可用，采用同步双写(主从都持久化后再返回ACK)。

3. 消费者。 消费完成后，才向服务器返回ack (Rocket默认的)



**RocketMQ怎么避免消息重复消费**

消息重复消费的原因，如何做幂等



**消息堆积怎么办**

1. 消费者问题。消费者挂了需要重启；Topic中消息队列的数量大于消费者的数量，这时候可以考虑添加消费者(如果有DB等操作，要考虑下游是否支撑得住)
2. MQ问题。Topic中消息队列的数量小于消费者的数量，这时候添加消费者是没有用的。这时应该新建Topic指定消息队列的数量，然后将消息转移到新的Topic中，最后添加消费者，消费新Topic中的消息。



**消息怎么过滤**

1. 通过Tag过滤
2. 通过SQL



**消息是如何发送的**



**消费者如何接收消息**



**如何确保消息被接受了**

生产者保证消息发送到了Broker，Broker保证消息被消费。



**RocketMQ怎么使用顺序消息**

* 全局顺序：需要将Topic的消息队列数量设置成1
* 局部顺序：相同业务的消息需要发送到相同的消息队列中。需要使用MessageQueueSelector来选择要发送的Queue，即对业务编号进行hash，然后根据队列数量对hash值取余，将消息发送到一个queue中。(调用send方法的时候指定MessageQueueSelector)

1. 生产者：相同业务发送到相同的Queue中
2. 消费者：要保证消息顺序消费，同一个queue就只能被一个消费者所消费，因此对broker中消费队列加锁是无法避免的(消费客户端先向broker端发起对messageQueue的加锁请求，只有加锁成功时才创建pullRequest进行消息拉取，下面看下lock加锁请求方法)。使用MessageListenerOrderly监听器



**延迟队列的使用**

发消息时。设置delayLevel等级即可。

rocketmq实现的延时队列只支持特定的延时时间段，1s,5s,10s,...2h，不能支持任意时间段的延时。定时消息会暂存在名为SCHEDULE_TOPIC_XXXX的topic中，定时扫描，时间到后再添加到指定的Topic。



**消息怎么重试**

1. 生产者，可以设置Producer重试的次数，在指定时间内消息没有发送成功时就会重试。还不行就在catch中将消息存入DB的补偿表中
2. 消费者，消费者失败分两种情况：Exception和超时。消费者的重试实际是Broker的机制。消费者返回消息消费失败后Broker会把消息放到一个延时队列中取，Broker重试会放到不同的延时队列中，随着重试次数的增加，它重试的间隔会不断的变长，直至进入死信队列，就不在给消费者发送这条消息。超时是Broker没收到ACK，它认为没有发送就会一直发送消息。



**消费者因某些原因无法解决的消息怎么办**

返回成功，然后将消息存入补偿表中。



**消息基于什么传输的**



**怎么设计一个MQ**

1. 可伸缩
2. 持久化
3. 高可用



**死信队列的原因，使用**

消息重试超过一定次数后（默认16次）就会被放到死信队列中，不会再被消费者正常消费。有效期与正常消息相同，均为 3 天，3 天后会被自动删除。因此，请在死信消息产生后的 3天内及时处理。排查可疑因素并解决问题后，可以在消息队列 RocketMQ 控制台重新发送该消息，让消费者重新消费一次。



**消息补偿机制是什么**

1. 消息发送失败，将消息存在了DB中，定时的将DB中的消息取出来重新发送(或者直接让消费者来查)，发送成功后修改补偿表中消息的状态，失败后等待下一次的补偿。1、如果是同步发送MQ消息，则在try catch代码块中catch部分，执行保存入库操作；2、如果是异步发送MQ消息，则在SendCallback接口的public void onException(Throwable e) {}方法，执行保存入库操作。

表结构设计：

Id,topic,tag,property,status,exception,create_time,update_time



**优先级队列**

由于RocketMQ所有消息都是持久化的，所以如果按照优先级来排序，开销会非常大，因此RocketMQ没有特意支持消息优先级。好像目前要实现严格的优先级也只能用不同topic了。



**事务消息**

保证本地事务和消息的发送都成功



**怎么做消峰**



**Broker是怎么保存消息的**

 RocketMQ主要的存储文件包括commitlog文件、consumequeue文件、indexfile文件。 

Broker在收到消息之后，会把消息保存到commitlog的文件当中，而同时在分布式的存储当中，每个broker都会保存一部分topic的数据，同时，每个topic对应的messagequeue下都会生成consumequeue文件用于保存commitlog的物理位置偏移量offset，indexfile中会保存key和offset的对应关系。

由于同一个topic的消息并不是连续的存储在commitlog中，消费者如果直接从commitlog获取消息效率非常低，所以通过consumequeue保存commitlog中消息的偏移量的物理地址，这样消费者在消费的时候先从consumequeue中根据偏移量定位到具体的commitlog物理文件，然后根据一定的规则（offset和文件大小取模）在commitlog中快速定位。


**Master和Slave之间是怎么同步数据的呢**



**RocketMQ速度快的原因**

是因为使用了顺序存储、Page Cache和异步刷盘。

1. 我们在写入commitlog的时候是顺序写入的，这样比随机写入的性能就会提高很多
2. 写入commitlog的时候并不是直接写入磁盘，而是先写入操作系统的PageCache
3. 最后由操作系统异步将缓存中的数据刷到磁盘